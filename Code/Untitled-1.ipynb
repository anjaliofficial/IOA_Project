{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a04b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate user_id count: 0\n",
      "Shape after cleaning: (691, 14)\n",
      "Saved cleaned CSV to: datawave_music_cleaned_full.csv\n",
      "Overall churn rate: 0.3054\n",
      "\n",
      "Churn rate by subscription_type:\n",
      " subscription_type\n",
      "family     0.323671\n",
      "premium    0.315217\n",
      "student    0.306533\n",
      "free       0.247525\n",
      "Name: churned, dtype: float64\n",
      "Saved plot: plot_churn_by_subscription.png\n",
      "Saved plot: plot_listening_dist.png\n",
      "Saved plot: plot_satisfaction_by_churn.png\n",
      "Saved plot: plot_listening_by_churn.png\n",
      "Saved plot: plot_skiprate_by_churn.png\n",
      "Saved plot: plot_age_dist.png\n",
      "\n",
      "Training churn model (Logistic Regression) with class_weight='balanced'...\n",
      "Accuracy: 0.4797687861271676\n",
      "ROC AUC: 0.4979559748427673\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.49      0.57       120\n",
      "           1       0.28      0.45      0.35        53\n",
      "\n",
      "    accuracy                           0.48       173\n",
      "   macro avg       0.48      0.47      0.46       173\n",
      "weighted avg       0.55      0.48      0.50       173\n",
      "\n",
      "Saved model to: churn_logreg_model_final_balanced.pkl\n",
      "Saved plot: plot_roc_curve_balanced.png\n",
      "Saved model coefficients to: model_coefficients_balanced.csv\n",
      "\n",
      "Pipeline complete. Key outputs in: .\n",
      "Cleaned CSV: datawave_music_cleaned_full.csv\n",
      "Model file: churn_logreg_model_final_balanced.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, roc_curve, auc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === CONFIG ===\n",
    "# This line is where the filename is set\n",
    "INPUT_CSV = \"DataWave_Music_Sprint_Dataset.csv\" \n",
    "OUTPUT_DIR = Path(\".\") \n",
    "TODAY = pd.Timestamp(\"2025-11-25\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === HELPERS (Excluding safe_read_csv) ===\n",
    "def save_plot(fig, fname):\n",
    "    path = OUTPUT_DIR / fname\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=150)\n",
    "    print(f\"Saved plot: {path}\")\n",
    "\n",
    "# === LOAD (Using direct pandas read) ===\n",
    "print(\"Loading data from:\", INPUT_CSV)\n",
    "try:\n",
    "    # Direct read, confirmed to work in the execution environment\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "except FileNotFoundError as e:\n",
    "    # If this still fails in your local environment, you may need to \n",
    "    # adjust the INPUT_CSV path to include your file's local directory.\n",
    "    print(f\"Error reading file: {e}\")\n",
    "    print(\"Please ensure 'DataWave_Music_Sprint_Dataset.csv' is in the same folder as your script.\")\n",
    "    raise\n",
    "\n",
    "print(\"Initial shape:\", df.shape)\n",
    "\n",
    "\n",
    "# === STANDARDIZE COLUMN NAMES & COMMON RENAMES ===\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "col_map = {\n",
    "    'avg_listening_hours_per_week': 'avg_listening_hours_per_week',\n",
    "    'hours_listened': 'avg_listening_hours_per_week',\n",
    "    'join_date': 'join_date',\n",
    "    'datejoined': 'join_date',\n",
    "    'date_joined': 'join_date',\n",
    "    'last_active_date': 'last_active',\n",
    "    'churn': 'churned',\n",
    "    'churned?': 'churned'\n",
    "}\n",
    "df.rename(columns=col_map, inplace=True)\n",
    "\n",
    "# Ensure columns exist\n",
    "for c in ['subscription_type','gender','country']:\n",
    "    if c not in df.columns:\n",
    "        df[c] = 'unknown'\n",
    "\n",
    "# === STRING CLEANING: subscription_type, gender, country ===\n",
    "df['subscription_type'] = df['subscription_type'].astype(str).str.strip().str.lower()\n",
    "subs_fix = {\n",
    "    'premum': 'premium', 'premiun': 'premium', 'prem': 'premium',\n",
    "    'premu m': 'premium', 'premium ': 'premium',\n",
    "    'fam': 'family', 'family ': 'family',\n",
    "    'studnt': 'student', 'student ': 'student'\n",
    "}\n",
    "df['subscription_type'] = df['subscription_type'].replace(subs_fix).fillna('unknown')\n",
    "\n",
    "df['gender'] = df['gender'].astype(str).str.strip().str.lower().replace({'f':'female','m':'male','nan':'unknown','': 'unknown'}).fillna('unknown')\n",
    "df['country'] = df['country'].astype(str).str.strip().replace({'': 'Unknown', 'nan':'Unknown'}).fillna('Unknown').str.title()\n",
    "\n",
    "# === NUMERIC CONVERSIONS ===\n",
    "num_map = {\n",
    "    'age': 'age',\n",
    "    'avg_listening_hours_per_week': 'avg_listening_hours_per_week',\n",
    "    'total_songs_played': 'total_songs_played',\n",
    "    'satisfaction_score': 'satisfaction_score',\n",
    "    'monthly_fee': 'monthly_fee'\n",
    "}\n",
    "for col in num_map:\n",
    "    if col in df.columns:\n",
    "        # Include replacement for 'USD' and commas\n",
    "        df[col] = pd.to_numeric(\n",
    "            df[col].astype(str).str.replace('USD', '', regex=False).str.replace(',', '').str.strip(),\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "# === SKIP RATE PARSING ===\n",
    "if 'skip_rate' in df.columns:\n",
    "    def parse_skip(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        s = str(x).strip()\n",
    "        # Remove percent sign\n",
    "        if s.endswith('%'):\n",
    "            s2 = s[:-1].strip()\n",
    "            try:\n",
    "                return float(s2)\n",
    "            except:\n",
    "                return np.nan\n",
    "        # if decimal between 0 and 1 treat as fraction -> percent\n",
    "        try:\n",
    "            v = float(s)\n",
    "            if 0 <= v <= 1:\n",
    "                return v * 100.0\n",
    "            return v\n",
    "        except:\n",
    "            return np.nan\n",
    "    df['skip_rate_pct'] = df['skip_rate'].apply(parse_skip)\n",
    "else:\n",
    "    df['skip_rate_pct'] = np.nan\n",
    "\n",
    "# If skip_rate_pct entirely missing, create column and fill later\n",
    "df['skip_rate_pct'] = pd.to_numeric(df['skip_rate_pct'], errors='coerce')\n",
    "\n",
    "# === CHURN CONVERSION ===\n",
    "if 'churned' in df.columns:\n",
    "    df['churned'] = df['churned'].astype(str).str.lower().str.strip()\n",
    "    df['churned'] = df['churned'].replace({'yes':1, 'no':0, 'true':1, 'false':0, '1':1, '0':0})\n",
    "    df['churned'] = pd.to_numeric(df['churned'], errors='coerce')\n",
    "    df['churned'] = df['churned'].fillna(0).astype(int)\n",
    "else:\n",
    "    df['churned'] = 0\n",
    "\n",
    "# === DATES: join_date and tenure ===\n",
    "if 'join_date' in df.columns:\n",
    "    # try parse with default (month-first) then fallback to day-first for unparsed strings\n",
    "    df['join_date_parsed'] = pd.to_datetime(df['join_date'], errors='coerce', dayfirst=False)\n",
    "    mask_na = df['join_date_parsed'].isna() & df['join_date'].notna()\n",
    "    if mask_na.any():\n",
    "        try:\n",
    "            df.loc[mask_na, 'join_date_parsed'] = pd.to_datetime(df.loc[mask_na, 'join_date'], errors='coerce', dayfirst=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "    df['join_date'] = df['join_date_parsed']\n",
    "    df.drop(columns=['join_date_parsed'], inplace=True)\n",
    "else:\n",
    "    df['join_date'] = pd.NaT\n",
    "\n",
    "df['tenure_days'] = (TODAY - df['join_date']).dt.days\n",
    "# keep tenure_days numeric (NaN where join_date missing)\n",
    "\n",
    "# === DUPLICATES: user_id ===\n",
    "if 'user_id' in df.columns:\n",
    "    dup_count = df['user_id'].duplicated().sum()\n",
    "    print(\"Duplicate user_id count:\", dup_count)\n",
    "    if dup_count > 0:\n",
    "        df = df.drop_duplicates(subset=['user_id'], keep='first')\n",
    "\n",
    "# === HANDLE MISSING VALUES ===\n",
    "# Fill categorical with 'unknown'\n",
    "df['subscription_type'] = df['subscription_type'].fillna('unknown')\n",
    "df['gender'] = df['gender'].fillna('unknown')\n",
    "df['country'] = df['country'].fillna('Unknown')\n",
    "\n",
    "df['monthly_fee'] = df['monthly_fee'].fillna(0.0)\n",
    "\n",
    "# Fill numeric with medians (if median NaN -> 0)\n",
    "numeric_fill_cols = [\n",
    "    'age','avg_listening_hours_per_week','total_songs_played',\n",
    "    'satisfaction_score','monthly_fee','skip_rate_pct','tenure_days'\n",
    "]\n",
    "for c in numeric_fill_cols:\n",
    "    if c in df.columns:\n",
    "        med = df[c].median()\n",
    "        if pd.isna(med):\n",
    "            med = 0.0\n",
    "        df[c] = df[c].fillna(med)\n",
    "\n",
    "# === REMOVE UNREALISTIC OUTLIERS ===\n",
    "if 'age' in df.columns:\n",
    "    df = df[(df['age'] >= 10) & (df['age'] <= 90)]\n",
    "if 'avg_listening_hours_per_week' in df.columns:\n",
    "    df = df[(df['avg_listening_hours_per_week'] >= 0) & (df['avg_listening_hours_per_week'] <= 200)]\n",
    "\n",
    "print(\"Shape after cleaning:\", df.shape)\n",
    "\n",
    "# === FINAL SUBSCRIPTION NORMALIZATION ===\n",
    "df['subscription_type'] = df['subscription_type'].replace({\n",
    "    'fam': 'family', 'family ': 'family', 'studnt': 'student', 'student ': 'student'\n",
    "}).str.lower()\n",
    "\n",
    "# === SAVE CLEANED CSV ===\n",
    "clean_path = OUTPUT_DIR / \"datawave_music_cleaned_full.csv\"\n",
    "df.to_csv(clean_path, index=False)\n",
    "print(\"Saved cleaned CSV to:\", clean_path)\n",
    "\n",
    "\n",
    "\n",
    "# === EXPLORATORY ANALYSIS & PLOTS ===\n",
    "overall_churn = df['churned'].mean()\n",
    "print(f\"Overall churn rate: {overall_churn:.4f}\")\n",
    "\n",
    "# Churn rate  by subscription type\n",
    "churn_by_sub = df.groupby('subscription_type')['churned'].mean().sort_values(ascending=False)\n",
    "print(\"\\nChurn rate by subscription_type:\\n\", churn_by_sub)\n",
    "\n",
    "# plot churn by subscription\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = churn_by_sub.plot(kind='bar', rot=30)\n",
    "ax.set_title(\"Churn rate by subscription_type\")\n",
    "ax.set_ylabel(\"Churn rate\")\n",
    "save_plot(fig, \"plot_churn_by_subscription.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# listening distribution\n",
    "if 'avg_listening_hours_per_week' in df.columns:\n",
    "    fig = plt.figure(figsize=(7,4))\n",
    "    df['avg_listening_hours_per_week'].plot(kind='hist', bins=30)\n",
    "    plt.title(\"Distribution of Avg Listening Hours per Week\")\n",
    "    plt.xlabel(\"Avg listening hours per week\")\n",
    "    save_plot(fig, \"plot_listening_dist.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# satisfaction by churn boxplot\n",
    "if 'satisfaction_score' in df.columns:\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    df.loc[:,['satisfaction_score', 'churned']].boxplot(column='satisfaction_score', by='churned', ax=fig.gca())\n",
    "    plt.title(\"Satisfaction score by churn status\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Churned (0=No, 1=Yes)\")\n",
    "    plt.ylabel(\"Satisfaction score\")\n",
    "    save_plot(fig, \"plot_satisfaction_by_churn.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# avg listening by churn\n",
    "if 'avg_listening_hours_per_week' in df.columns:\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    df.groupby('churned')['avg_listening_hours_per_week'].mean().plot(kind='bar', rot=0)\n",
    "    plt.title(\"Avg listening hours by churn status\")\n",
    "    plt.xlabel(\"Churned (0=No, 1=Yes)\")\n",
    "    plt.ylabel(\"Avg listening hours per week\")\n",
    "    save_plot(fig, \"plot_listening_by_churn.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# skip rate by churn\n",
    "if 'skip_rate_pct' in df.columns:\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    df.groupby('churned')['skip_rate_pct'].mean().plot(kind='bar', rot=0)\n",
    "    plt.title(\"Skip rate (%) by churn status\")\n",
    "    plt.xlabel(\"Churned (0=No, 1=Yes)\")\n",
    "    plt.ylabel(\"Skip rate (%)\")\n",
    "    save_plot(fig, \"plot_skiprate_by_churn.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# age distribution\n",
    "if 'age' in df.columns:\n",
    "    fig = plt.figure(figsize=(7,4))\n",
    "    df['age'].plot(kind='hist', bins=20)\n",
    "    plt.title(\"Age distribution\")\n",
    "    plt.xlabel(\"Age\")\n",
    "    save_plot(fig, \"plot_age_dist.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# === SIMPLE CHURN MODEL (Logistic Regression) ===\n",
    "print(\"\\nTraining churn model (Logistic Regression) with class_weight='balanced'...\")\n",
    "\n",
    "feature_cols = ['age','avg_listening_hours_per_week','total_songs_played','skip_rate_pct','satisfaction_score','monthly_fee','tenure_days']\n",
    "feature_cols = [c for c in feature_cols if c in df.columns]\n",
    "\n",
    "if not feature_cols:\n",
    "    raise RuntimeError(\"No numeric features available for modeling.\")\n",
    "\n",
    "X = df[feature_cols + ['subscription_type','gender']].copy()\n",
    "y = df['churned'].copy()\n",
    "\n",
    "# One-hot categorical, scale numeric\n",
    "cat_cols = ['subscription_type','gender']\n",
    "num_cols = feature_cols\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# ADDED: class_weight='balanced' to handle class imbalance\n",
    "clf = Pipeline(steps=[\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=500, solver='liblinear', class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "except ValueError:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:,1] if hasattr(clf.named_steps['clf'], \"predict_proba\") else np.zeros(len(y_test))\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "roc = roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) > 1 else float('nan')\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"ROC AUC:\", roc)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Save model\n",
    "model_path = OUTPUT_DIR / \"churn_logreg_model_final_balanced.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "print(\"Saved model to:\", model_path)\n",
    "\n",
    "# Plot ROC if possible\n",
    "if len(np.unique(y_test)) > 1:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1], linestyle='--')\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    save_plot(fig, \"plot_roc_curve_balanced.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# Save coefficients (numeric + ohe names)\n",
    "ohe = clf.named_steps['pre'].named_transformers_['cat']\n",
    "try:\n",
    "    ohe_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "except Exception:\n",
    "    ohe_names = []\n",
    "transformed_cols = num_cols + ohe_names\n",
    "coefs = clf.named_steps['clf'].coef_[0]\n",
    "coef_df = pd.DataFrame({'feature': transformed_cols, 'coef': coefs[:len(transformed_cols)]})\n",
    "coef_out = OUTPUT_DIR / \"model_coefficients_balanced.csv\"\n",
    "coef_df.to_csv(coef_out, index=False)\n",
    "print(\"Saved model coefficients to:\", coef_out)\n",
    "\n",
    "print(\"\\nPipeline complete. Key outputs in:\", OUTPUT_DIR)\n",
    "print(\"Cleaned CSV:\", clean_path)\n",
    "print(\"Model file:\", model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
